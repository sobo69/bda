{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G_snPLP50Viu"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
        "from pyspark.ml.clustering import KMeans\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "# 1. Initialize Spark Session\n",
        "spark = SparkSession.builder.appName(\"CustomerKMeansClustering\").getOrCreate()\n",
        "\n",
        "# 2. Load dataset\n",
        "file_path = \"Customer_Data.csv\"  # adjust as needed\n",
        "df = spark.read.csv(file_path, header=True, inferSchema=True)\n",
        "\n",
        "# 3. Choose two numeric features to cluster on (e.g. BALANCE and PURCHASES)\n",
        "features = [\"BALANCE\", \"PURCHASES\"]\n",
        "\n",
        "# 4. Assemble features into a single vector column\n",
        "assembler = VectorAssembler(inputCols=features, outputCol=\"rawFeatures\")\n",
        "assembled = assembler.transform(df).na.drop()  # drop any rows with nulls\n",
        "\n",
        "# 5. Standardize the feature vectors\n",
        "scaler = StandardScaler(\n",
        "    inputCol=\"rawFeatures\",\n",
        "    outputCol=\"features\",\n",
        "    withStd=True,\n",
        "    withMean=False\n",
        ")\n",
        "scaler_model = scaler.fit(assembled)\n",
        "scaled = scaler_model.transform(assembled)\n",
        "\n",
        "# 6. Elbow Method: compute WSSSE for k = 2…10\n",
        "wssse_list = []\n",
        "print(\"=== Elbow Method (WSSSE) ===\")\n",
        "for k in range(2, 11):\n",
        "    km = KMeans(featuresCol=\"features\", k=k, seed=42)\n",
        "    model = km.fit(scaled)\n",
        "    cost = model.summary.trainingCost\n",
        "    wssse_list.append((k, cost))\n",
        "    print(f\"k={k:2d}, WSSSE={cost:.3f}\")\n",
        "print(\"============================\\n\")\n",
        "\n",
        "# 7. Manually set optimal_k based on the elbow plot\n",
        "optimal_k = 3  # ← update this after you inspect the printed WSSSE\n",
        "\n",
        "# 8. Fit final KMeans model\n",
        "km_final = KMeans(featuresCol=\"features\", k=optimal_k, seed=42)\n",
        "model_final = km_final.fit(scaled)\n",
        "clusters = model_final.transform(scaled)\n",
        "\n",
        "# 9. Show a sample of BALANCE, PURCHASES and assigned cluster\n",
        "print(\"=== Sample cluster assignments ===\")\n",
        "clusters.select(\"BALANCE\", \"PURCHASES\", \"prediction\").show(10, truncate=False)\n",
        "\n",
        "# 10. Convert to pandas for plotting\n",
        "clusters_pd = clusters.select(\"BALANCE\", \"PURCHASES\", \"prediction\").toPandas()\n",
        "\n",
        "# 11. Recover original-scale centroids\n",
        "#     Note: scaler_model.std is a DenseVector of std devs\n",
        "std_vector = scaler_model.std.toArray()\n",
        "scaled_centers = np.array(model_final.clusterCenters())\n",
        "orig_centers = scaled_centers * std_vector  # inverse scaling\n",
        "\n",
        "# 12. Plot clusters with seaborn + centroids\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.scatterplot(\n",
        "    data=clusters_pd,\n",
        "    x=\"BALANCE\", y=\"PURCHASES\",\n",
        "    hue=\"prediction\", palette=\"tab10\", s=50\n",
        ")\n",
        "plt.scatter(\n",
        "    orig_centers[:, 0], orig_centers[:, 1],\n",
        "    marker='X', s=200, color='red', label='Centroids'\n",
        ")\n",
        "plt.title(f\"K-Means Clustering on Customer Data (k={optimal_k})\")\n",
        "plt.xlabel(\"Balance\")\n",
        "plt.ylabel(\"Purchases\")\n",
        "plt.legend(title=\"Cluster\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 13. Stop Spark session\n",
        "spark.stop()\n"
      ]
    }
  ]
}